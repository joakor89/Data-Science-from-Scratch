{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "989cc8b3",
   "metadata": {},
   "source": [
    "# Chapter 13 - Naives Bayes\n",
    "\n",
    "### A Really Dumb Spam Filter\n",
    "\n",
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0cedf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Set\n",
    "from typing import NamedTuple\n",
    "from typing import List, Tuple, Dict, Iterable\n",
    "import re\n",
    "import math\n",
    "import requests\n",
    "import tarfile\n",
    "from io import BytesIO\n",
    "import glob, re\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0391c7b",
   "metadata": {},
   "source": [
    "### A Really Dumb Spam Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0baec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(S|B) = [P(B|S)P(S)/[P(B|S)P(S) + P(B|9,-S)P(-S)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f187fa",
   "metadata": {},
   "source": [
    "### A more Sophisticated Spam Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d93d607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(S|X = x) = P(X = x|S)/[P(X = x|S) + P(X = x|-S)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17091fd7",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d312e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> Set[str]:\n",
    "    text = text.lower()\n",
    "    all_words = re.findall(\"[a-z0-9]+\", text)\n",
    "    return set(all_words)\n",
    "\n",
    "assert tokenize(\"Data Science is science\") == {\"data\", \"science\", \"is\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af6be198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message(NamedTuple):\n",
    "    text: str\n",
    "    is_spam: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58bf72bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, k: float = 0.5) -> None:\n",
    "        self.k = k\n",
    "        \n",
    "        self.tokens: Set[str] = set()\n",
    "        self.token_spam_counts: Dict[str, int] = defaultdict(int)\n",
    "        self.token_ham_counts: Dict[str, int] = defaultdict(int)\n",
    "        self.spam_message = self.ham_message = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4114d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, messages: Iterable[Message]) -> None:\n",
    "    for message in message:\n",
    "        # Increment message counts\n",
    "        if message.is_spam:\n",
    "            self.spam_messages += 1\n",
    "        else:\n",
    "            self.ham_messages += 1\n",
    "            \n",
    "        # Increment word counts\n",
    "        for token in tokenize(message.text):\n",
    "            self.tokens.add(token)\n",
    "            if message.is_spam:\n",
    "                self.token_spam_counts[token] =+ 1\n",
    "            else:\n",
    "                self.token_ham_counts[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fc58c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Private\" Helper Function\n",
    "\n",
    "def _probabilities(self, toke: str) -> Tuple[float, float]:\n",
    "    spam = self.token_spam_counts[token]\n",
    "    ham = self.token_ham_counts[token]\n",
    "    \n",
    "    p_token_spam = (spam + self.k) / (self.spam_messages + 2 * self.k)\n",
    "    p_token_ham = (ham + self.k) / (self.ham_messages + 2 * self.k)\n",
    "    \n",
    "    return p_token_spam, p_token_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "463b6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, text: str) -> float:\n",
    "    text_tokens = tokenize(text)\n",
    "    log_prob_if_spam = log_prob_if_ham = 0.0\n",
    "    \n",
    "    # Iterate through each word in our vocabulary\n",
    "    for token in self.tokens:\n",
    "        prob_if_spam, prob_if_ham = self._probabilities(token)\n",
    "        \n",
    "        if token in text_tokens:\n",
    "            log_prob_if_spam += math.log(prob_if_spam)\n",
    "            log_prob_if_ham += math.log(prob_if_ham)\n",
    "        else:\n",
    "            log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
    "            log_prob_if_ham += math.log(1.0 - prob_if_ham)\n",
    "            prob_if_spam = math.exp(log_prob_if_spam)\n",
    "            prob_if_ham = math.exp(log_prob_if_ham)\n",
    "            return prob_if_spam / (prob_if_spam + prob_if_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f439701",
   "metadata": {},
   "source": [
    "### Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "477d007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [Message(\"spam rules\", is_spam=True),\n",
    "           Message(\"ham rules\", is_spam=False),\n",
    "           Message(\"hello ham\", is_spam=False)]\n",
    "\n",
    "model = NaiveBayesClassifier(k=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e1a0cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40b57117",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.tokens == {\"spam\", \"ham\", \"rules\", \"hello\"}\n",
    "assert model.spam_messages == 1\n",
    "assert model.ham_messages == 2\n",
    "assert model.token_spam_counts == {\"spam\": 1, \"rules\": 1}\n",
    "assert model.token_ham_counts == {\"ham\": 2, \"rules\": 1, \"hello\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "792c9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"hello spam\"\n",
    "\n",
    "prof_if_spam = [\n",
    "    (1 + 0.5) / (1 + 2 * 0.5),\n",
    "    1 - (0 + 0.5) / (1 + 2 * 0.5),\n",
    "    1 - (1 + 0.5) / (1 + 2 * 0.5),\n",
    "    (0 + 0.5) / (1 + 2 * 0.5),\n",
    "]\n",
    "\n",
    "prof_if_ham = [\n",
    "    (0 + 0.5) / (2 + 2 * 0.5),\n",
    "    1 - (2 + 0.5) / (2 + 2 * 0.5),\n",
    "    1 - (1 + 0.5) / (2 + 2 * 0.5),\n",
    "    (1 + 0.5) / (2 + 2 * 0.5),\n",
    "]\n",
    "\n",
    "p_if_spam = math.exp(sum(math.log(p) for p in probs_if_spam))\n",
    "p_if_ham = math.exp(sum(math.log(p) for p in probs_if_ham))\n",
    "\n",
    "assert model.predict(text) == p_if_spam / (p_if_spam + p_if_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f655392",
   "metadata": {},
   "source": [
    "### Using Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4af656aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://spamassassin.apache.org/old/publiccorpus\"\n",
    "FILES = [\"20021010_easy_ham.tar/bz2\",\n",
    "         \"20021010_hard_ham.tar/bz2\",\n",
    "         \"20021010_spam.tar/bz2\"]\n",
    "OUTPUT_DIR = 'spam_data'\n",
    "\n",
    "for filename in FILES:\n",
    "    content = requests.get(f\"{BASE_URL}/{filename}\").content\n",
    "    \n",
    "    fin = BytesIO(content)\n",
    "    \n",
    "    with tarfile.open(fileobj=fin, mode='r:bz2') as tf:\n",
    "        tf.extractall(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "852b952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "757951e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'spam_data/*/*'\n",
    "\n",
    "data = List[Message] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db5b505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in glob.glob(path):\n",
    "    is_spam = \"ham\" not in filename\n",
    "    \n",
    "    with open(filename, errors='ignore') as email_file:\n",
    "        for line in email_file:\n",
    "            if line.startswith(\"Subject\"):\n",
    "                subject = line.lstrip(\"Subject: \")\n",
    "                data.append(Message(subject, is_spam))\n",
    "                breakrandom.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e13da4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = TypeVar('X')  # generic type to represent a data point\n",
    "\n",
    "def split_data(data: List[X], prob: float) -> Tuple[List[X], List[X]]:\n",
    "    \"\"\"Split data into fractions [prob, 1 - prob]\"\"\"\n",
    "    data = data[:]                    # Make a shallow copy\n",
    "    random.shuffle(data)              # because shuffle modifies the list.\n",
    "    cut = int(len(data) * prob)       # Use prob to find a cutoff\n",
    "    return data[:cut], data[cut:]     # and split the shuffled list there.\n",
    "\n",
    "data = [n for n in range(1000)]\n",
    "train, test = split_data(data, 0.75)\n",
    "\n",
    "# The proportions should be correct\n",
    "assert len(train) == 750\n",
    "assert len(test) == 250\n",
    "\n",
    "# And the original data should be preserved (in some order)\n",
    "assert sorted(train + test) == data\n",
    "\n",
    "Y = TypeVar('Y')  # generic type to represent output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e8e2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "train_message, test_messages = split_data(data, 0.75)\n",
    "\n",
    "model = NaiveBayesClassifier()\n",
    "model.train(train_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f918b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [(message, model.predict(message.text))\n",
    "               for message in test_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e87e13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = Counter((message.is_spam, spam_probability > 0.5)\n",
    "                           for message, spam_probability in predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c1a9651",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "713b059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_soam_given_token(token:str, model: NaiveBayesClassifier) -> float:\n",
    "    prob_if_spam, prob_if_ham = model._probabilities(token)\n",
    "    \n",
    "    return prob_if_spam / (prob_if_spam + prb_if_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bcb194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(model.tokens, key=lambda t: p_spam_given_token(t, model))\n",
    "\n",
    "print(\"spammiest_words\", words[-10])\n",
    "print(\"hammiest_words\", words[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
